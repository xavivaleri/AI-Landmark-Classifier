{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landmark Classification with CNN\n",
    "\n",
    "### A simple app\n",
    "\n",
    "In this notebook we build a very simple app that uses our exported model.\n",
    "\n",
    "### Test our app\n",
    "Using a search engine for images (like Google Images) download images of some of the landmarks, like the Eiffel Tower, the Golden Gate Bridge, Machu Picchu and so on. Save a few examples locally, then upload them to your app to see how the model behaves!\n",
    "\n",
    "The app will show the top 5 classes that the model think are most relevant for the picture you have uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497a8db4ee05449fa4be5f89e2f38885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Please upload a picture of a landmark'), FileUpload(value={}, description='Upload'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import VBox, Button, FileUpload, Output, Label\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import io\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "\n",
    "# Decide which model you want to use among the ones exported\n",
    "learn_inf = torch.jit.load(\"checkpoints/transfer_exported.pt\")# YOUR CODE HERE\n",
    "\n",
    "def on_click_classify(change):\n",
    "\n",
    "    # Load image that has been uploaded\n",
    "    fn = io.BytesIO(btn_upload.data[-1])\n",
    "\n",
    "    img = Image.open(fn)\n",
    "    img.load()\n",
    "\n",
    "    # Let's clear the previous output (if any)\n",
    "    out_pl.clear_output()\n",
    "\n",
    "    # Display the image\n",
    "    with out_pl:\n",
    "\n",
    "        ratio = img.size[0] / img.size[1]\n",
    "        c = img.copy()\n",
    "        c.thumbnail([ratio * 200, 200])\n",
    "        display(c)\n",
    "\n",
    "    # Transform to tensor\n",
    "    timg = T.ToTensor()(img).unsqueeze_(0)\n",
    "\n",
    "    # Calling the model\n",
    "    softmax = learn_inf(timg).data.cpu().numpy().squeeze()\n",
    "    \n",
    "    # Get the indexes of the classes ordered by softmax\n",
    "    # (larger first)\n",
    "    idxs = np.argsort(softmax)[::-1]\n",
    "    \n",
    "    # Loop over the classes with the largest softmax\n",
    "    for i in range(5):\n",
    "        # Get softmax value\n",
    "        p = softmax[idxs[i]]\n",
    "    \n",
    "        # Get class name\n",
    "        landmark_name = learn_inf.class_names[idxs[i]]\n",
    "        \n",
    "        labels[i].value = f\"{landmark_name} (prob: {p:.2f})\"\n",
    "\n",
    "\n",
    "# Putting back btn_upload to a widget for next cell\n",
    "btn_upload = FileUpload()\n",
    "\n",
    "btn_run = Button(description=\"Classify\")\n",
    "btn_run.on_click(on_click_classify)\n",
    "\n",
    "labels = []\n",
    "for _ in range(5):\n",
    "    labels.append(Label())\n",
    "\n",
    "out_pl = Output()\n",
    "out_pl.clear_output()\n",
    "\n",
    "wgs = [Label(\"Please upload a picture of a landmark\"), btn_upload, btn_run, out_pl]\n",
    "wgs.extend(labels)\n",
    "\n",
    "VBox(wgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
